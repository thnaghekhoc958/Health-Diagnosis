from fastapi import FastAPI
from pydantic import BaseModel
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import os
import json

# ÄÆ°á»ng dáº«n Ä‘áº¿n file Ã¡nh xáº¡
label_file = os.path.join(os.path.dirname(__file__), "label_translations.json")

# Load Ã¡nh xáº¡ tá»« tiáº¿ng Anh sang tiáº¿ng Viá»‡t
with open(label_file, "r", encoding="utf-8") as f:
    label_translations = json.load(f)


app = FastAPI()

# === Load model & tokenizer ===
model_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "ModelTraning")
tokenizer = AutoTokenizer.from_pretrained(model_dir)
model = AutoModelForSequenceClassification.from_pretrained(model_dir)
model.eval()

# === Äá»c id2label tá»« model config vÃ  Ã©p kiá»ƒu key thÃ nh int ===
id2label = {int(k): v for k, v in model.config.id2label.items()}

# === Äá»‹nh nghÄ©a input dáº¡ng JSON gá»­i Ä‘áº¿n API ===
class SymptomInput(BaseModel):
    text: str
    language: str = "vi"
# === Endpoint xá»­ lÃ½ dá»± Ä‘oÃ¡n ===
@app.post("/predict")
def predict_symptom(data: SymptomInput):
    print("ğŸ”¥ Nháº­n tá»« NodeJS:", data.dict())  # In toÃ n bá»™ JSON Ä‘Ã£ parse
    inputs = tokenizer(data.text, return_tensors="pt", padding=True, truncation=True)
    with torch.no_grad():
        outputs = model(**inputs)
        predicted_class = torch.argmax(outputs.logits, dim=1).item()
        label_en = id2label[predicted_class]
        
        # Tráº£ káº¿t quáº£ theo ngÃ´n ngá»¯ Ä‘Æ°á»£c truyá»n vÃ o
        label = label_translations.get(label_en, label_en) if data.language == "vi" else label_en

    return {"label": label}
    
        
