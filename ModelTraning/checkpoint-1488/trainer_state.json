{
  "best_metric": 0.00804220698773861,
  "best_model_checkpoint": "C:\\Users\\1\\Music\\project ban_sach\\nodejs\\src\\AI\\ModelTraning\\checkpoint-1488",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 1488,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.020161290322580645,
      "grad_norm": 3.136624336242676,
      "learning_rate": 1.98991935483871e-05,
      "loss": 3.7044,
      "step": 10
    },
    {
      "epoch": 0.04032258064516129,
      "grad_norm": 3.3490326404571533,
      "learning_rate": 1.9798387096774193e-05,
      "loss": 3.6755,
      "step": 20
    },
    {
      "epoch": 0.06048387096774194,
      "grad_norm": 3.691274642944336,
      "learning_rate": 1.969758064516129e-05,
      "loss": 3.6197,
      "step": 30
    },
    {
      "epoch": 0.08064516129032258,
      "grad_norm": 4.736058235168457,
      "learning_rate": 1.9596774193548388e-05,
      "loss": 3.5553,
      "step": 40
    },
    {
      "epoch": 0.10080645161290322,
      "grad_norm": 4.892001628875732,
      "learning_rate": 1.9495967741935485e-05,
      "loss": 3.4882,
      "step": 50
    },
    {
      "epoch": 0.12096774193548387,
      "grad_norm": 4.723971366882324,
      "learning_rate": 1.9395161290322583e-05,
      "loss": 3.3957,
      "step": 60
    },
    {
      "epoch": 0.14112903225806453,
      "grad_norm": 6.005794048309326,
      "learning_rate": 1.929435483870968e-05,
      "loss": 3.3327,
      "step": 70
    },
    {
      "epoch": 0.16129032258064516,
      "grad_norm": 5.931492328643799,
      "learning_rate": 1.9193548387096777e-05,
      "loss": 3.1764,
      "step": 80
    },
    {
      "epoch": 0.1814516129032258,
      "grad_norm": 6.111090183258057,
      "learning_rate": 1.909274193548387e-05,
      "loss": 3.0687,
      "step": 90
    },
    {
      "epoch": 0.20161290322580644,
      "grad_norm": 10.133498191833496,
      "learning_rate": 1.899193548387097e-05,
      "loss": 3.0091,
      "step": 100
    },
    {
      "epoch": 0.2217741935483871,
      "grad_norm": 5.893524646759033,
      "learning_rate": 1.8891129032258066e-05,
      "loss": 2.7974,
      "step": 110
    },
    {
      "epoch": 0.24193548387096775,
      "grad_norm": 6.923588275909424,
      "learning_rate": 1.8790322580645163e-05,
      "loss": 2.769,
      "step": 120
    },
    {
      "epoch": 0.2620967741935484,
      "grad_norm": 9.647502899169922,
      "learning_rate": 1.8689516129032257e-05,
      "loss": 2.6496,
      "step": 130
    },
    {
      "epoch": 0.28225806451612906,
      "grad_norm": 7.278018951416016,
      "learning_rate": 1.8588709677419355e-05,
      "loss": 2.5044,
      "step": 140
    },
    {
      "epoch": 0.3024193548387097,
      "grad_norm": 7.483063220977783,
      "learning_rate": 1.8487903225806452e-05,
      "loss": 2.4014,
      "step": 150
    },
    {
      "epoch": 0.3225806451612903,
      "grad_norm": 7.298105239868164,
      "learning_rate": 1.838709677419355e-05,
      "loss": 2.35,
      "step": 160
    },
    {
      "epoch": 0.34274193548387094,
      "grad_norm": 6.753427505493164,
      "learning_rate": 1.8286290322580647e-05,
      "loss": 2.1651,
      "step": 170
    },
    {
      "epoch": 0.3629032258064516,
      "grad_norm": 7.105449199676514,
      "learning_rate": 1.8185483870967744e-05,
      "loss": 2.0802,
      "step": 180
    },
    {
      "epoch": 0.38306451612903225,
      "grad_norm": 7.526661396026611,
      "learning_rate": 1.808467741935484e-05,
      "loss": 1.9965,
      "step": 190
    },
    {
      "epoch": 0.4032258064516129,
      "grad_norm": 7.266362190246582,
      "learning_rate": 1.7983870967741936e-05,
      "loss": 1.8852,
      "step": 200
    },
    {
      "epoch": 0.42338709677419356,
      "grad_norm": 6.570189476013184,
      "learning_rate": 1.7883064516129033e-05,
      "loss": 1.7643,
      "step": 210
    },
    {
      "epoch": 0.4435483870967742,
      "grad_norm": 6.973808765411377,
      "learning_rate": 1.778225806451613e-05,
      "loss": 1.6761,
      "step": 220
    },
    {
      "epoch": 0.4637096774193548,
      "grad_norm": 7.104538917541504,
      "learning_rate": 1.7681451612903228e-05,
      "loss": 1.599,
      "step": 230
    },
    {
      "epoch": 0.4838709677419355,
      "grad_norm": 7.17194128036499,
      "learning_rate": 1.7580645161290325e-05,
      "loss": 1.4998,
      "step": 240
    },
    {
      "epoch": 0.5040322580645161,
      "grad_norm": 6.601029872894287,
      "learning_rate": 1.7479838709677423e-05,
      "loss": 1.3953,
      "step": 250
    },
    {
      "epoch": 0.5241935483870968,
      "grad_norm": 6.846442699432373,
      "learning_rate": 1.7379032258064517e-05,
      "loss": 1.3123,
      "step": 260
    },
    {
      "epoch": 0.5443548387096774,
      "grad_norm": 7.803072929382324,
      "learning_rate": 1.7278225806451614e-05,
      "loss": 1.2405,
      "step": 270
    },
    {
      "epoch": 0.5645161290322581,
      "grad_norm": 7.259261131286621,
      "learning_rate": 1.717741935483871e-05,
      "loss": 1.2064,
      "step": 280
    },
    {
      "epoch": 0.5846774193548387,
      "grad_norm": 5.242786407470703,
      "learning_rate": 1.707661290322581e-05,
      "loss": 1.0195,
      "step": 290
    },
    {
      "epoch": 0.6048387096774194,
      "grad_norm": 6.03490686416626,
      "learning_rate": 1.6975806451612903e-05,
      "loss": 1.0472,
      "step": 300
    },
    {
      "epoch": 0.625,
      "grad_norm": 5.334771633148193,
      "learning_rate": 1.6875e-05,
      "loss": 1.0011,
      "step": 310
    },
    {
      "epoch": 0.6451612903225806,
      "grad_norm": 4.503767013549805,
      "learning_rate": 1.6774193548387098e-05,
      "loss": 0.9205,
      "step": 320
    },
    {
      "epoch": 0.6653225806451613,
      "grad_norm": 6.079460144042969,
      "learning_rate": 1.6673387096774195e-05,
      "loss": 0.8491,
      "step": 330
    },
    {
      "epoch": 0.6854838709677419,
      "grad_norm": 5.927882671356201,
      "learning_rate": 1.6572580645161292e-05,
      "loss": 0.7861,
      "step": 340
    },
    {
      "epoch": 0.7056451612903226,
      "grad_norm": 3.6285550594329834,
      "learning_rate": 1.647177419354839e-05,
      "loss": 0.6777,
      "step": 350
    },
    {
      "epoch": 0.7258064516129032,
      "grad_norm": 5.225587844848633,
      "learning_rate": 1.6370967741935487e-05,
      "loss": 0.6802,
      "step": 360
    },
    {
      "epoch": 0.7459677419354839,
      "grad_norm": 4.674576759338379,
      "learning_rate": 1.627016129032258e-05,
      "loss": 0.6486,
      "step": 370
    },
    {
      "epoch": 0.7661290322580645,
      "grad_norm": 4.959657669067383,
      "learning_rate": 1.616935483870968e-05,
      "loss": 0.6005,
      "step": 380
    },
    {
      "epoch": 0.7862903225806451,
      "grad_norm": 4.115506172180176,
      "learning_rate": 1.6068548387096776e-05,
      "loss": 0.5649,
      "step": 390
    },
    {
      "epoch": 0.8064516129032258,
      "grad_norm": 3.583181381225586,
      "learning_rate": 1.596774193548387e-05,
      "loss": 0.5406,
      "step": 400
    },
    {
      "epoch": 0.8266129032258065,
      "grad_norm": 4.080550193786621,
      "learning_rate": 1.5866935483870967e-05,
      "loss": 0.479,
      "step": 410
    },
    {
      "epoch": 0.8467741935483871,
      "grad_norm": 3.3079497814178467,
      "learning_rate": 1.5766129032258065e-05,
      "loss": 0.4702,
      "step": 420
    },
    {
      "epoch": 0.8669354838709677,
      "grad_norm": 2.932504177093506,
      "learning_rate": 1.5665322580645162e-05,
      "loss": 0.4416,
      "step": 430
    },
    {
      "epoch": 0.8870967741935484,
      "grad_norm": 2.8135793209075928,
      "learning_rate": 1.556451612903226e-05,
      "loss": 0.3892,
      "step": 440
    },
    {
      "epoch": 0.907258064516129,
      "grad_norm": 3.74310302734375,
      "learning_rate": 1.5463709677419357e-05,
      "loss": 0.3577,
      "step": 450
    },
    {
      "epoch": 0.9274193548387096,
      "grad_norm": 2.7063632011413574,
      "learning_rate": 1.5362903225806454e-05,
      "loss": 0.3408,
      "step": 460
    },
    {
      "epoch": 0.9475806451612904,
      "grad_norm": 2.219148635864258,
      "learning_rate": 1.5262096774193548e-05,
      "loss": 0.2909,
      "step": 470
    },
    {
      "epoch": 0.967741935483871,
      "grad_norm": 2.4303195476531982,
      "learning_rate": 1.5161290322580646e-05,
      "loss": 0.2786,
      "step": 480
    },
    {
      "epoch": 0.9879032258064516,
      "grad_norm": 2.5246057510375977,
      "learning_rate": 1.5060483870967743e-05,
      "loss": 0.2652,
      "step": 490
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 1.0,
      "eval_loss": 0.1828983575105667,
      "eval_runtime": 106.7514,
      "eval_samples_per_second": 9.302,
      "eval_steps_per_second": 1.171,
      "step": 496
    },
    {
      "epoch": 1.0080645161290323,
      "grad_norm": 2.0360612869262695,
      "learning_rate": 1.4959677419354839e-05,
      "loss": 0.2412,
      "step": 500
    },
    {
      "epoch": 1.028225806451613,
      "grad_norm": 2.137479543685913,
      "learning_rate": 1.4858870967741936e-05,
      "loss": 0.2394,
      "step": 510
    },
    {
      "epoch": 1.0483870967741935,
      "grad_norm": 2.0223517417907715,
      "learning_rate": 1.4758064516129033e-05,
      "loss": 0.2212,
      "step": 520
    },
    {
      "epoch": 1.0685483870967742,
      "grad_norm": 1.9506261348724365,
      "learning_rate": 1.465725806451613e-05,
      "loss": 0.2013,
      "step": 530
    },
    {
      "epoch": 1.0887096774193548,
      "grad_norm": 2.152144432067871,
      "learning_rate": 1.4556451612903226e-05,
      "loss": 0.1846,
      "step": 540
    },
    {
      "epoch": 1.1088709677419355,
      "grad_norm": 1.3464508056640625,
      "learning_rate": 1.4455645161290324e-05,
      "loss": 0.1638,
      "step": 550
    },
    {
      "epoch": 1.129032258064516,
      "grad_norm": 1.3901444673538208,
      "learning_rate": 1.4354838709677421e-05,
      "loss": 0.1591,
      "step": 560
    },
    {
      "epoch": 1.1491935483870968,
      "grad_norm": 1.2883983850479126,
      "learning_rate": 1.4254032258064517e-05,
      "loss": 0.15,
      "step": 570
    },
    {
      "epoch": 1.1693548387096775,
      "grad_norm": 1.246310830116272,
      "learning_rate": 1.4153225806451614e-05,
      "loss": 0.1488,
      "step": 580
    },
    {
      "epoch": 1.189516129032258,
      "grad_norm": 1.1684719324111938,
      "learning_rate": 1.4052419354838712e-05,
      "loss": 0.1345,
      "step": 590
    },
    {
      "epoch": 1.2096774193548387,
      "grad_norm": 1.2254199981689453,
      "learning_rate": 1.3951612903225809e-05,
      "loss": 0.1169,
      "step": 600
    },
    {
      "epoch": 1.2298387096774193,
      "grad_norm": 0.9336628317832947,
      "learning_rate": 1.3850806451612903e-05,
      "loss": 0.1017,
      "step": 610
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.0367114543914795,
      "learning_rate": 1.375e-05,
      "loss": 0.1131,
      "step": 620
    },
    {
      "epoch": 1.2701612903225805,
      "grad_norm": 1.6473338603973389,
      "learning_rate": 1.3649193548387098e-05,
      "loss": 0.0986,
      "step": 630
    },
    {
      "epoch": 1.2903225806451613,
      "grad_norm": 0.8581101298332214,
      "learning_rate": 1.3548387096774194e-05,
      "loss": 0.0852,
      "step": 640
    },
    {
      "epoch": 1.310483870967742,
      "grad_norm": 0.8565931916236877,
      "learning_rate": 1.3447580645161291e-05,
      "loss": 0.0897,
      "step": 650
    },
    {
      "epoch": 1.3306451612903225,
      "grad_norm": 0.5704967975616455,
      "learning_rate": 1.3346774193548388e-05,
      "loss": 0.0892,
      "step": 660
    },
    {
      "epoch": 1.3508064516129032,
      "grad_norm": 1.1026902198791504,
      "learning_rate": 1.3245967741935486e-05,
      "loss": 0.0752,
      "step": 670
    },
    {
      "epoch": 1.370967741935484,
      "grad_norm": 0.863555371761322,
      "learning_rate": 1.3145161290322581e-05,
      "loss": 0.0738,
      "step": 680
    },
    {
      "epoch": 1.3911290322580645,
      "grad_norm": 0.9202122092247009,
      "learning_rate": 1.3044354838709679e-05,
      "loss": 0.0715,
      "step": 690
    },
    {
      "epoch": 1.4112903225806452,
      "grad_norm": 0.7045688629150391,
      "learning_rate": 1.2943548387096776e-05,
      "loss": 0.0677,
      "step": 700
    },
    {
      "epoch": 1.4314516129032258,
      "grad_norm": 0.9554975628852844,
      "learning_rate": 1.2842741935483872e-05,
      "loss": 0.0647,
      "step": 710
    },
    {
      "epoch": 1.4516129032258065,
      "grad_norm": 0.6535918712615967,
      "learning_rate": 1.274193548387097e-05,
      "loss": 0.0635,
      "step": 720
    },
    {
      "epoch": 1.471774193548387,
      "grad_norm": 0.7462558746337891,
      "learning_rate": 1.2641129032258067e-05,
      "loss": 0.0563,
      "step": 730
    },
    {
      "epoch": 1.4919354838709677,
      "grad_norm": 0.47731176018714905,
      "learning_rate": 1.2540322580645164e-05,
      "loss": 0.0542,
      "step": 740
    },
    {
      "epoch": 1.5120967741935485,
      "grad_norm": 0.5690246224403381,
      "learning_rate": 1.2439516129032258e-05,
      "loss": 0.0491,
      "step": 750
    },
    {
      "epoch": 1.532258064516129,
      "grad_norm": 0.5393521189689636,
      "learning_rate": 1.2338709677419355e-05,
      "loss": 0.0471,
      "step": 760
    },
    {
      "epoch": 1.5524193548387095,
      "grad_norm": 0.5886905789375305,
      "learning_rate": 1.2237903225806453e-05,
      "loss": 0.0473,
      "step": 770
    },
    {
      "epoch": 1.5725806451612905,
      "grad_norm": 0.4386565089225769,
      "learning_rate": 1.2137096774193548e-05,
      "loss": 0.0453,
      "step": 780
    },
    {
      "epoch": 1.592741935483871,
      "grad_norm": 0.48318442702293396,
      "learning_rate": 1.2036290322580646e-05,
      "loss": 0.0439,
      "step": 790
    },
    {
      "epoch": 1.6129032258064515,
      "grad_norm": 0.5201834440231323,
      "learning_rate": 1.1935483870967743e-05,
      "loss": 0.0409,
      "step": 800
    },
    {
      "epoch": 1.6330645161290323,
      "grad_norm": 0.44158869981765747,
      "learning_rate": 1.1834677419354839e-05,
      "loss": 0.0409,
      "step": 810
    },
    {
      "epoch": 1.653225806451613,
      "grad_norm": 0.43883129954338074,
      "learning_rate": 1.1733870967741936e-05,
      "loss": 0.0408,
      "step": 820
    },
    {
      "epoch": 1.6733870967741935,
      "grad_norm": 0.3431914150714874,
      "learning_rate": 1.1633064516129034e-05,
      "loss": 0.0384,
      "step": 830
    },
    {
      "epoch": 1.6935483870967742,
      "grad_norm": 0.38675662875175476,
      "learning_rate": 1.1532258064516131e-05,
      "loss": 0.0369,
      "step": 840
    },
    {
      "epoch": 1.713709677419355,
      "grad_norm": 0.38712048530578613,
      "learning_rate": 1.1431451612903227e-05,
      "loss": 0.0337,
      "step": 850
    },
    {
      "epoch": 1.7338709677419355,
      "grad_norm": 0.36879271268844604,
      "learning_rate": 1.1330645161290324e-05,
      "loss": 0.0316,
      "step": 860
    },
    {
      "epoch": 1.754032258064516,
      "grad_norm": 0.3122998774051666,
      "learning_rate": 1.1229838709677422e-05,
      "loss": 0.0322,
      "step": 870
    },
    {
      "epoch": 1.7741935483870968,
      "grad_norm": 0.5237480998039246,
      "learning_rate": 1.1129032258064516e-05,
      "loss": 0.0354,
      "step": 880
    },
    {
      "epoch": 1.7943548387096775,
      "grad_norm": 0.40052086114883423,
      "learning_rate": 1.1028225806451613e-05,
      "loss": 0.0349,
      "step": 890
    },
    {
      "epoch": 1.814516129032258,
      "grad_norm": 0.3699108958244324,
      "learning_rate": 1.092741935483871e-05,
      "loss": 0.0319,
      "step": 900
    },
    {
      "epoch": 1.8346774193548387,
      "grad_norm": 0.2731659710407257,
      "learning_rate": 1.0826612903225808e-05,
      "loss": 0.0278,
      "step": 910
    },
    {
      "epoch": 1.8548387096774195,
      "grad_norm": 0.3303219974040985,
      "learning_rate": 1.0725806451612903e-05,
      "loss": 0.0299,
      "step": 920
    },
    {
      "epoch": 1.875,
      "grad_norm": 0.3057163953781128,
      "learning_rate": 1.0625e-05,
      "loss": 0.0273,
      "step": 930
    },
    {
      "epoch": 1.8951612903225805,
      "grad_norm": 0.34552082419395447,
      "learning_rate": 1.0524193548387098e-05,
      "loss": 0.0295,
      "step": 940
    },
    {
      "epoch": 1.9153225806451613,
      "grad_norm": 0.3189723491668701,
      "learning_rate": 1.0423387096774194e-05,
      "loss": 0.0281,
      "step": 950
    },
    {
      "epoch": 1.935483870967742,
      "grad_norm": 0.3538338840007782,
      "learning_rate": 1.0322580645161291e-05,
      "loss": 0.0259,
      "step": 960
    },
    {
      "epoch": 1.9556451612903225,
      "grad_norm": 0.34469208121299744,
      "learning_rate": 1.0221774193548389e-05,
      "loss": 0.0259,
      "step": 970
    },
    {
      "epoch": 1.9758064516129032,
      "grad_norm": 0.4223226010799408,
      "learning_rate": 1.0120967741935486e-05,
      "loss": 0.029,
      "step": 980
    },
    {
      "epoch": 1.995967741935484,
      "grad_norm": 0.38147664070129395,
      "learning_rate": 1.0020161290322582e-05,
      "loss": 0.0259,
      "step": 990
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 1.0,
      "eval_loss": 0.015837622806429863,
      "eval_runtime": 278.6999,
      "eval_samples_per_second": 3.563,
      "eval_steps_per_second": 0.449,
      "step": 992
    },
    {
      "epoch": 2.0161290322580645,
      "grad_norm": 0.28840553760528564,
      "learning_rate": 9.919354838709679e-06,
      "loss": 0.0232,
      "step": 1000
    },
    {
      "epoch": 2.036290322580645,
      "grad_norm": 0.29883506894111633,
      "learning_rate": 9.818548387096775e-06,
      "loss": 0.023,
      "step": 1010
    },
    {
      "epoch": 2.056451612903226,
      "grad_norm": 0.32498180866241455,
      "learning_rate": 9.717741935483872e-06,
      "loss": 0.0225,
      "step": 1020
    },
    {
      "epoch": 2.0766129032258065,
      "grad_norm": 0.29890358448028564,
      "learning_rate": 9.616935483870968e-06,
      "loss": 0.0231,
      "step": 1030
    },
    {
      "epoch": 2.096774193548387,
      "grad_norm": 0.27091625332832336,
      "learning_rate": 9.516129032258065e-06,
      "loss": 0.0227,
      "step": 1040
    },
    {
      "epoch": 2.1169354838709675,
      "grad_norm": 0.2730257213115692,
      "learning_rate": 9.415322580645163e-06,
      "loss": 0.0217,
      "step": 1050
    },
    {
      "epoch": 2.1370967741935485,
      "grad_norm": 0.2577078342437744,
      "learning_rate": 9.314516129032258e-06,
      "loss": 0.0229,
      "step": 1060
    },
    {
      "epoch": 2.157258064516129,
      "grad_norm": 0.22590899467468262,
      "learning_rate": 9.213709677419356e-06,
      "loss": 0.0209,
      "step": 1070
    },
    {
      "epoch": 2.1774193548387095,
      "grad_norm": 0.20156821608543396,
      "learning_rate": 9.112903225806451e-06,
      "loss": 0.0215,
      "step": 1080
    },
    {
      "epoch": 2.1975806451612905,
      "grad_norm": 0.26466551423072815,
      "learning_rate": 9.012096774193549e-06,
      "loss": 0.0203,
      "step": 1090
    },
    {
      "epoch": 2.217741935483871,
      "grad_norm": 0.23772281408309937,
      "learning_rate": 8.911290322580646e-06,
      "loss": 0.0211,
      "step": 1100
    },
    {
      "epoch": 2.2379032258064515,
      "grad_norm": 0.38521161675453186,
      "learning_rate": 8.810483870967744e-06,
      "loss": 0.0208,
      "step": 1110
    },
    {
      "epoch": 2.258064516129032,
      "grad_norm": 0.16869710385799408,
      "learning_rate": 8.70967741935484e-06,
      "loss": 0.0182,
      "step": 1120
    },
    {
      "epoch": 2.278225806451613,
      "grad_norm": 0.24740754067897797,
      "learning_rate": 8.608870967741937e-06,
      "loss": 0.0188,
      "step": 1130
    },
    {
      "epoch": 2.2983870967741935,
      "grad_norm": 0.19184720516204834,
      "learning_rate": 8.508064516129034e-06,
      "loss": 0.0194,
      "step": 1140
    },
    {
      "epoch": 2.318548387096774,
      "grad_norm": 0.2336009442806244,
      "learning_rate": 8.40725806451613e-06,
      "loss": 0.0194,
      "step": 1150
    },
    {
      "epoch": 2.338709677419355,
      "grad_norm": 0.1771191656589508,
      "learning_rate": 8.306451612903227e-06,
      "loss": 0.0178,
      "step": 1160
    },
    {
      "epoch": 2.3588709677419355,
      "grad_norm": 0.2783851623535156,
      "learning_rate": 8.205645161290323e-06,
      "loss": 0.0195,
      "step": 1170
    },
    {
      "epoch": 2.379032258064516,
      "grad_norm": 0.18284888565540314,
      "learning_rate": 8.10483870967742e-06,
      "loss": 0.0175,
      "step": 1180
    },
    {
      "epoch": 2.399193548387097,
      "grad_norm": 0.21966390311717987,
      "learning_rate": 8.004032258064518e-06,
      "loss": 0.0159,
      "step": 1190
    },
    {
      "epoch": 2.4193548387096775,
      "grad_norm": 0.355498731136322,
      "learning_rate": 7.903225806451613e-06,
      "loss": 0.0174,
      "step": 1200
    },
    {
      "epoch": 2.439516129032258,
      "grad_norm": 0.16922682523727417,
      "learning_rate": 7.80241935483871e-06,
      "loss": 0.0162,
      "step": 1210
    },
    {
      "epoch": 2.4596774193548385,
      "grad_norm": 0.19729790091514587,
      "learning_rate": 7.701612903225806e-06,
      "loss": 0.0159,
      "step": 1220
    },
    {
      "epoch": 2.4798387096774195,
      "grad_norm": 0.17488352954387665,
      "learning_rate": 7.6008064516129045e-06,
      "loss": 0.0166,
      "step": 1230
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.25581446290016174,
      "learning_rate": 7.500000000000001e-06,
      "loss": 0.0172,
      "step": 1240
    },
    {
      "epoch": 2.5201612903225805,
      "grad_norm": 0.18193891644477844,
      "learning_rate": 7.399193548387097e-06,
      "loss": 0.0167,
      "step": 1250
    },
    {
      "epoch": 2.540322580645161,
      "grad_norm": 0.16407771408557892,
      "learning_rate": 7.298387096774194e-06,
      "loss": 0.0163,
      "step": 1260
    },
    {
      "epoch": 2.560483870967742,
      "grad_norm": 0.22392572462558746,
      "learning_rate": 7.197580645161291e-06,
      "loss": 0.0165,
      "step": 1270
    },
    {
      "epoch": 2.5806451612903225,
      "grad_norm": 0.16692985594272614,
      "learning_rate": 7.096774193548388e-06,
      "loss": 0.0163,
      "step": 1280
    },
    {
      "epoch": 2.600806451612903,
      "grad_norm": 0.12357373535633087,
      "learning_rate": 6.9959677419354846e-06,
      "loss": 0.0163,
      "step": 1290
    },
    {
      "epoch": 2.620967741935484,
      "grad_norm": 0.253587543964386,
      "learning_rate": 6.895161290322582e-06,
      "loss": 0.0152,
      "step": 1300
    },
    {
      "epoch": 2.6411290322580645,
      "grad_norm": 0.15514211356639862,
      "learning_rate": 6.794354838709678e-06,
      "loss": 0.015,
      "step": 1310
    },
    {
      "epoch": 2.661290322580645,
      "grad_norm": 0.19420494139194489,
      "learning_rate": 6.693548387096774e-06,
      "loss": 0.0147,
      "step": 1320
    },
    {
      "epoch": 2.681451612903226,
      "grad_norm": 0.14557816088199615,
      "learning_rate": 6.5927419354838716e-06,
      "loss": 0.0151,
      "step": 1330
    },
    {
      "epoch": 2.7016129032258065,
      "grad_norm": 0.13108694553375244,
      "learning_rate": 6.491935483870968e-06,
      "loss": 0.0137,
      "step": 1340
    },
    {
      "epoch": 2.721774193548387,
      "grad_norm": 0.154326930642128,
      "learning_rate": 6.3911290322580655e-06,
      "loss": 0.0158,
      "step": 1350
    },
    {
      "epoch": 2.741935483870968,
      "grad_norm": 0.15314075350761414,
      "learning_rate": 6.290322580645162e-06,
      "loss": 0.0139,
      "step": 1360
    },
    {
      "epoch": 2.7620967741935485,
      "grad_norm": 0.20269560813903809,
      "learning_rate": 6.189516129032258e-06,
      "loss": 0.0148,
      "step": 1370
    },
    {
      "epoch": 2.782258064516129,
      "grad_norm": 0.1924046277999878,
      "learning_rate": 6.088709677419355e-06,
      "loss": 0.0141,
      "step": 1380
    },
    {
      "epoch": 2.8024193548387095,
      "grad_norm": 0.13110367953777313,
      "learning_rate": 5.987903225806452e-06,
      "loss": 0.0139,
      "step": 1390
    },
    {
      "epoch": 2.8225806451612905,
      "grad_norm": 0.21669654548168182,
      "learning_rate": 5.887096774193549e-06,
      "loss": 0.0141,
      "step": 1400
    },
    {
      "epoch": 2.842741935483871,
      "grad_norm": 0.16666416823863983,
      "learning_rate": 5.7862903225806456e-06,
      "loss": 0.0142,
      "step": 1410
    },
    {
      "epoch": 2.8629032258064515,
      "grad_norm": 0.1411251574754715,
      "learning_rate": 5.685483870967743e-06,
      "loss": 0.0128,
      "step": 1420
    },
    {
      "epoch": 2.883064516129032,
      "grad_norm": 0.1651855856180191,
      "learning_rate": 5.5846774193548395e-06,
      "loss": 0.0139,
      "step": 1430
    },
    {
      "epoch": 2.903225806451613,
      "grad_norm": 0.1589111089706421,
      "learning_rate": 5.483870967741935e-06,
      "loss": 0.0142,
      "step": 1440
    },
    {
      "epoch": 2.9233870967741935,
      "grad_norm": 0.16213339567184448,
      "learning_rate": 5.3830645161290326e-06,
      "loss": 0.0131,
      "step": 1450
    },
    {
      "epoch": 2.943548387096774,
      "grad_norm": 0.18455281853675842,
      "learning_rate": 5.282258064516129e-06,
      "loss": 0.0139,
      "step": 1460
    },
    {
      "epoch": 2.963709677419355,
      "grad_norm": 0.1553022563457489,
      "learning_rate": 5.1814516129032265e-06,
      "loss": 0.0127,
      "step": 1470
    },
    {
      "epoch": 2.9838709677419355,
      "grad_norm": 0.1429862380027771,
      "learning_rate": 5.080645161290323e-06,
      "loss": 0.0131,
      "step": 1480
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 1.0,
      "eval_loss": 0.00804220698773861,
      "eval_runtime": 289.7101,
      "eval_samples_per_second": 3.428,
      "eval_steps_per_second": 0.431,
      "step": 1488
    }
  ],
  "logging_steps": 10,
  "max_steps": 1984,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 788994328559616.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
